# â™»ï¸ Classificador de ResÃ­duos ReciclÃ¡veis com VisÃ£o Computacional

Este projeto desenvolve um modelo de visÃ£o computacional capaz de identificar o tipo de resÃ­duo (papel, plÃ¡stico, vidro e metal) a partir de uma imagem. A soluÃ§Ã£o foi criada para auxiliar cooperativas de reciclagem a aumentar produtividade e reduzir erros na triagem manual.

---

## ğŸ¯ Objetivo
Criar um protÃ³tipo funcional capaz de:
1. Receber uma imagem enviada pelo usuÃ¡rio.
2. Classificar o tipo de material usando um modelo CNN com transfer learning.
3. Exibir probabilidades por classe.
4. Rodar em CPU com baixo custo computacional.

---

## ğŸ’¡ MotivaÃ§Ã£o
A triagem manual Ã© lenta e sujeita a erro. Um classificador automÃ¡tico pode ajudar cooperativas a separar materiais de forma mais eficiente, reduzindo desperdÃ­cio e aumentando valor de venda.

---

## ğŸ“ Dataset
Utilizamos a combinaÃ§Ã£o de trÃªs datasets:
1. TrashNet
2. Garbage Classification Dataset
3. Waste Vision Dataset

As classes finais:
- `papel`
- `plastico`
- `vidro`
- `metal`

### ğŸ“¦ A estrutura dos dados:

| Classe      | Treino | ValidaÃ§Ã£o | Total |
|-------------|--------|-----------|-------|
| **Papel**   | 210    | 50        | 260   |
| **PlÃ¡stico**| 133    | 30        | 163   |
| **Vidro**   | 403    | 100       | 503   |
| **Metal**   | 154    | 40        | 194   |

---

## ğŸ§  Arquitetura da SoluÃ§Ã£o
1. OrganizaÃ§Ã£o do dataset em subpastas por classe.
2. AumentaÃ§Ã£o com rotaÃ§Ã£o leve, variaÃ§Ã£o de brilho e recortes aleatÃ³rios.
3. Transfer learning com ResNet18 prÃ©-treinada no ImageNet.
4. Treinamos apenas o classificador final para acelerar o processo.
5. MÃ©trica principal: **F1 macro.**

---

## ğŸ§ª Resultados

### ğŸ” VisÃ£o geral do melhor modelo

- **Ã‰pocas de treino:** 5  
- **Loss de validaÃ§Ã£o (melhor Ã©poca):** 0.3867  
- **F1 macro (melhor Ã©poca):** 0.8393  
- **AcurÃ¡cia de validaÃ§Ã£o:** 86%  
- **Tempo mÃ©dio de inferÃªncia:** ~0.3s em CPU  
- **Modelo salvo em:** `models/model.pth`  
- **Classes treinadas:** `['metal', 'papel', 'plastico', 'vidro']`

O modelo foi treinado com transferÃªncia de aprendizado usando ResNet18 e avaliado em um conjunto de validaÃ§Ã£o com 900 imagens.

---

### ğŸ“‹ RelatÃ³rio de ClassificaÃ§Ã£o (ValidaÃ§Ã£o)

| Classe      | PrecisÃ£o | Recall | F1-score | Suporte |
|------------|----------|--------|----------|---------|
| **Metal**  | 0.75     | 0.85   | 0.80     | 154     |
| **Papel**  | 0.95     | 0.88   | 0.91     | 210     |
| **PlÃ¡stico** | 0.87   | 0.65   | 0.75     | 133     |
| **Vidro**  | 0.87     | 0.93   | 0.90     | 403     |
| **MÃ©dia macro** | â€“   | â€“      | **0.84** | 900     |

### Principais insights

- O modelo apresenta **bom equilÃ­brio entre as classes**, com F1 macro em torno de 0.84.  
- **Papel e vidro** sÃ£o as classes com melhor desempenho, com F1 perto de 0.90.  
- **Metal** tem F1 de 0.80, com bom recall (recupera a maior parte dos metais) e alguma perda de precisÃ£o.  
- **PlÃ¡stico** Ã© a classe mais desafiadora, com recall menor, indicando que parte dos plÃ¡sticos ainda Ã© confundida com outras classes.  

Esses resultados sÃ£o adequados para um protÃ³tipo de hackathon e indicam espaÃ§o claro para evoluÃ§Ã£o com mais dados e ajustes especÃ­ficos para a classe â€œplÃ¡sticoâ€.

---

## âš™ï¸ Tecnologias Utilizadas
- Python 3.10+
- PyTorch
- Torchvision
- Scikit-learn
- Streamlit
- Pillow
- Numpy

---

## ğŸš€ Como Rodar

Crie um ambiente virtual e instale as dependÃªncias:

```bash
pip install -r requirements.txt
```

Certifique-se de que o dataset estÃ¡ organizado em `data/train` e `data/valid` conforme descrito acima.

Execute o treinamento:

```bash
python train.py
```

Isso irÃ¡ salvar o modelo treinado em `models/model.pth`.

Em seguida, rode o app:

```bash
streamlit run app.py
```

---

## ğŸ“Œ PrÃ³ximos Passos
1. Integrar GradCAM para interpretabilidade.
2. Expandir classes para incluir orgÃ¢nico e papelÃ£o.
3. Testar modelo em cÃ¢mera de celular para triagem em tempo real.

---

<!-- InÃ­cio da seÃ§Ã£o "Contato" -->
<h2>ğŸŒ Contate-me: </h2>
<div>
  <p>Developed by <b>FÃ¡bio Nogueira</b></p>
</div>
<p>
<a href="https://www.linkedin.com/in/faanogueira/" target="_blank"><img style="padding-right: 10px;" src="https://img.icons8.com/?size=100&id=13930&format=png&color=000000" target="_blank" width="80"></a>
<a href="https://github.com/faanogueira" target="_blank"><img style="padding-right: 10px;" src="https://img.icons8.com/?size=100&id=AZOZNnY73haj&format=png&color=000000" target="_blank" width="80"></a>
<a href="https://api.whatsapp.com/send?phone=5571983937557" target="_blank"><img style="padding-right: 10px;" src="https://img.icons8.com/?size=100&id=16713&format=png&color=000000" target="_blank" width="80"></a>
<a href="mailto:faanogueira@gmail.com"><img style="padding-right: 10px;" src="https://img.icons8.com/?size=100&id=P7UIlhbpWzZm&format=png&color=000000" target="_blank" width="80"></a> 
</p>
<!-- Fim da seÃ§Ã£o "Contato" -->